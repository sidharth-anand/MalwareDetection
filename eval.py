import os
import random

from datetime import datetime

import argparse
import numpy as np
import tensorflow as tf

import core.run

from core.config import DatasetConfig
from core.utils import DatasetUtils

from utils.confusion import plot_confusion_matrix

def parse_args():
    parser = argparse.ArgumentParser('Malware Detection - Evaluation')

    parser.add_argument('--dataset-path', type=str, required=True, help='Path to the dataset')
    parser.add_argument('--model-path', type=str, required=True, help='Path to the trained model')
    parser.add_argument('--output-path', type=str, required=True, help='Path to the save the evaluation results')

    parser.add_argument('--train-split', type=int, required=False, default=80, help='Train split')
    parser.add_argument('--validation-split', type=int, required=False, default=20, help='Validation split')
    parser.add_argument('--test-split', type=int, required=False, default=0, help='Test split')
    parser.add_argument('--batch-size', type=int, required=False, default=64, help='Batch size')
    parser.add_argument('--limit-dataset', type=int, required=False, default=0, help='Limit the dataset size')

    args = parser.parse_args()

    return args

def main():
    random.seed(1234)

    args = parse_args()

    if not len(args.model_path.split('_')) == 5:
        raise Exception('This checkpoint was not generated by this pipeline. Unable to load')

    (args.converter, args.model, args.resolution, args.resizer, args.sampler) = os.path.basename(args.model_path).split('_')
    args.resolution = int(args.resolution.split('x')[0])

    (ConverterClass, ModelClass, ResizerClass, SamplerClass) = core.run.get_classes(args.converter, args.model, args.resizer, args.sampler, args.resolution)

    resizer = ResizerClass(target_size=ModelClass.INPUT_SIZE)
    sampler = SamplerClass()
    
    config = DatasetConfig(args.train_split, args.validation_split, args.test_split, args.batch_size, args.limit_dataset)
    utils = DatasetUtils(resizer, sampler)

    dataset = ConverterClass(args.dataset_path, config, utils)
    model = ModelClass(dataset.num_classes)

    latest_checkpoint = tf.train.latest_checkpoint(args.model_path)
    model.load_weights(latest_checkpoint)

    model.compile(optimizer=model.get_optimizer(), loss=model.get_loss(), metrics=model.get_metrics())

    start = datetime.now()
    predictions = model.predict(dataset.validation_data, verbose=2, batch_size=1)
    end = datetime.now()
    print('Time ', (end - start).total_seconds())
    predictions = np.argmax(predictions, axis=1)

    labels = np.concatenate([y for _, y  in dataset.validation_data], axis=0)
    print('Len: ', len(labels))
    labels = np.argmax(labels, axis=1)

    confusion_matrix = tf.math.confusion_matrix(labels, predictions, dataset.num_classes)
    confusion_matrix_plot = plot_confusion_matrix(confusion_matrix.numpy(), list(dataset._get_classes().values()), os.path.basename(args.model_path))

    if not os.path.exists(args.output_path):
        os.mkdir(args.output_path)

    confusion_matrix_plot.savefig(f'{args.output_path}/{os.path.basename(args.model_path)}.png')

if __name__ == '__main__':
    main()
