import os
import random

import argparse
import tensorflow as tf

import core.run

from core.config import DatasetConfig
from core.utils import DatasetUtils

def parse_args():
    parser = argparse.ArgumentParser('Malware Detection - Evaluation')

    parser.add_argument('--dataset-path', type=str, required=True, help='Path to the dataset')
    parser.add_argument('--model-path', type=str, required=True, help='Path to the trained model')
    parser.add_argument('--output-path', type=str, required=True, help='Path to the save the evaluation results')

    parser.add_argument('--train-split', type=int, required=False, default=80, help='Train split')
    parser.add_argument('--validation-split', type=int, required=False, default=20, help='Validation split')
    parser.add_argument('--test-split', type=int, required=False, default=0, help='Test split')
    parser.add_argument('--batch-size', type=int, required=False, default=64, help='Batch size')
    parser.add_argument('--limit-dataset', type=int, required=False, default=0, help='Limit the dataset size')

    args = parser.parse_args()

    return args

def main():
    random.seed(1234)

    args = parse_args()

    if not len(args.model_path.split('_')) == 5:
        raise Exception('This checkpoint was not generated by this pipeline. Unable to load')

    (args.converter, args.model, args.resolution, args.resizer, args.sampler) = os.path.basename(args.model_path).split('_')
    args.resolution = int(args.resolution.split('x')[0])

    (ConverterClass, ModelClass, ResizerClass, SamplerClass) = core.run.get_classes(args.converter, args.model, args.resizer, args.sampler, args.resolution)

    resizer = ResizerClass(target_size=ModelClass.INPUT_SIZE)
    sampler = SamplerClass()
    
    config = DatasetConfig(args.train_split, args.validation_split, args.test_split, args.batch_size, args.limit_dataset)
    utils = DatasetUtils(resizer, sampler)

    dataset = ConverterClass(args.dataset_path, config, utils)
    model = ModelClass(dataset.num_classes)

    latest_checkpoint = tf.train.latest_checkpoint(args.model_path)
    model.load_weights(latest_checkpoint)

    model.compile(optimizer=model.get_optimizer(), loss=model.get_loss(), metrics=model.get_metrics())
    loss = model.evaluate(dataset.validation_data, verbose=2, batch_size=1)

if __name__ == '__main__':
    main()
