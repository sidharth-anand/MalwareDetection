import tensorflow as tf

from core.model import Model

class M6C1D_NP_Skip(Model):
    INPUT_SIZE = (256, 256)
    INPUT_CHANNELS = 1

    def __init__(self, num_classes: int) -> None:
        super().__init__()

        self.conv_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu, input_shape=(M6C1D_NP_Skip.INPUT_SIZE[0], M6C1D_NP_Skip.INPUT_SIZE[1], M6C1D_NP_Skip.INPUT_CHANNELS))
        self.conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu)
        self.conv_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu)
        self.conv_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu)
        self.conv_5 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu)
        self.conv_6 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), padding='valid', strides=(2, 2), activation=tf.keras.activations.relu)

        self.pool_1_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.pool_1_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.pool_1_3 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.pool_1_4 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.normalization_1 = tf.keras.layers.BatchNormalization()
        self.activation_1 = tf.keras.layers.ReLU()

        self.pool_2_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.pool_2_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))
        self.normalization_2 = tf.keras.layers.BatchNormalization()
        self.activation_2 = tf.keras.layers.ReLU()

        self.flatten = tf.keras.layers.Flatten()

        self.dense_1 = tf.keras.layers.Dense(units=16, activation=tf.keras.activations.relu)
        self.dropout_1 = tf.keras.layers.Dropout(rate=0.5)

        self.dense_output = tf.keras.layers.Dense(units=num_classes, activation=tf.keras.activations.softmax)

    def call(self, inputs: tf.Tensor) -> tf.Tensor:
        x = self.conv_1(inputs)
        skip_1 = x

        x = self.conv_2(x)
        skip_2 = x

        x = self.conv_3(x)
        x = self.conv_4(x)

        skip_2 = self.pool_2_1(skip_2)
        skip_2 = self.pool_2_2(skip_2)
        skip_2 = self.normalization_2(skip_2)
        skip_2 = self.activation_2(skip_2)
        x = tf.keras.layers.add([x, skip_2])

        x = self.conv_5(x)

        skip_1 = self.pool_1_1(skip_1)
        skip_1 = self.pool_1_2(skip_1)
        skip_1 = self.pool_1_3(skip_1)
        skip_1 = self.pool_1_4(skip_1)
        skip_1 = self.normalization_1(skip_1)
        skip_1 = self.activation_1(skip_1)
        x = tf.keras.layers.add([x, skip_1])

        x = self.conv_6(x)

        x = self.flatten(x)

        x = self.dense_1(x)
        x = self.dropout_1(x)
        x = self.dense_output(x)

        return x