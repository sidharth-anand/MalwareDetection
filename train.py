import glob
import importlib
import inspect
import typing
import os
import shutil

import argparse

from core.dataset import Dataset
from core.model import Model
from core.resizer import Resizer
from core.sampler import Sampler

from core.config import DatasetConfig
from core.utils import DatasetUtils

def get_choices_from_import(dir: str) -> typing.List[str]:
    choices = list(glob.glob(f'{dir}/*.py'))
    choices = [os.path.basename(choice).split('.')[0] for choice in choices]
    return choices

def parse_args():
    converter_choices = get_choices_from_import('converters')
    models_choices = get_choices_from_import('models')
    resizer_choices = get_choices_from_import('resizers')
    sampler_choices = get_choices_from_import('samplers')

    parser = argparse.ArgumentParser('Malware Detection - Trainer')

    parser.add_argument('--dataset-path', type=str, required=True, help='Path to the dataset')
    parser.add_argument('--checkpoint-path', type=str, required=False, default='checkpoints', help='Path to the save the trained model checkpoints')
    parser.add_argument('--log-path', type=str, required=False, default='logs', help='Path to the save the training logs')
    
    parser.add_argument('--converter', type=str, required=True, choices=converter_choices, help='Converter used on the dataset')
    parser.add_argument('--model', type=str, required=True, choices=models_choices, help='Model used on the dataset')
    parser.add_argument('--resizer', type=str, required=False, default='simple', choices=resizer_choices, help='Resizer used on the dataset')
    parser.add_argument('--sampler', type=str, required=False, default='raw', choices=sampler_choices, help='Upsampler/Downsampler for the channels used on the dataset')

    parser.add_argument('--train-split', type=int, required=False, default=60, help='Train split')
    parser.add_argument('--validation-split', type=int, required=False, default=20, help='Validation split')
    parser.add_argument('--test-split', type=int, required=False, default=20, help='Test split')
    parser.add_argument('--batch-size', type=int, required=False, default=32, help='Batch size')
    parser.add_argument('--epochs', type=int, required=False, default=10, help='Number of Epochs')
    parser.add_argument('--limit-dataset', type=int, required=False, default=0, help='Limit the dataset size')

    args = parser.parse_args()
    return args

def get_imported_class(filename: str, base_class):
    module = importlib.import_module(filename)
    classes = inspect.getmembers(module, inspect.isclass)

    for _, cls in classes:
        if issubclass(cls, base_class) and cls != base_class:
            return cls

    raise Exception(f'Could not find a exported class in {filename} which is a subclass of {base_class}')

def override_sampler_choice(output_channels: int, input_channels: int, sampler_choice: str) -> str:
    if not sampler_choice == 'raw':
        return sampler_choice
    
    if output_channels == 1 and input_channels == 3:
        print('You have chosen to not resample the channels in your image, but the model expects 3 channels and the dataset has 1. The default upsampler will be applied.')
        return 'upsampler'
    elif output_channels == 3 and input_channels == 1:
        print('You have chosen to not resample the channels in your image, but the model expects 1 channel and the dataset has 3. The default downsampler will be applied.')
        return 'downsampler'
    
    return 'raw'

def validate_sampler_choice(convert_output_channels: int, model_input_channels: int, sampler_class):
    if sampler_class.INPUT_CHANNELS == 0:
        sampler_class.INPUT_CHANNELS = convert_output_channels
    if sampler_class.OUTPUT_CHANNELS == 0:
        sampler_class.OUTPUT_CHANNELS = convert_output_channels
    
    if sampler_class.INPUT_CHANNELS != model_input_channels or sampler_class.OUTPUT_CHANNELS != convert_output_channels:
        raise Exception(f'Unable to use the sampler class {sampler_class.__name__} with the given converter/model. The model expects {model_input_channels} channels and the converter returns {convert_output_channels} channels.')

def main():
    args = parse_args()

    ConverterClass = get_imported_class(f'converters.{args.converter}', Dataset)
    ModelClass = get_imported_class(f'models.{args.model}', Model)
    ResizerClass = get_imported_class(f'resizers.{args.resizer}', Resizer)

    args.sampler = override_sampler_choice(ConverterClass.OUTPUT_CHANNELS, ModelClass.INPUT_CHANNELS, args.sampler)
    SamplerClass = get_imported_class(f'samplers.{args.sampler}', Sampler)
    validate_sampler_choice(ConverterClass.OUTPUT_CHANNELS, ModelClass.INPUT_CHANNELS, SamplerClass)

    resizer = ResizerClass(target_size=ModelClass.INPUT_SIZE)
    sampler = SamplerClass()
    
    config = DatasetConfig(args.train_split, args.validation_split, args.test_split, args.batch_size, args.limit_dataset)
    utils = DatasetUtils(resizer)

    dataset = ConverterClass(args.dataset_path, config, utils)
    model = ModelClass(dataset.num_classes)

    run_identifier = f'{args.converter}_{args.model}_{model.INPUT_SIZE[0]}x{model.INPUT_SIZE[1]}x{sampler.OUTPUT_CHANNELS}_{args.resizer}_{args.sampler}'

    log_path = os.path.join(args.log_path, run_identifier)
    checkpoint_path = os.path.join(args.checkpoint_path, run_identifier, 'epoch-{epoch}.model')

    if os.path.exists(log_path):
        shutil.rmtree(log_path)

    model.compile(optimizer=model.get_optimizer(), loss=model.get_loss(), metrics=model.get_metrics())
    model.fit(dataset.train_data, validation_data=dataset.validation_data, epochs=args.epochs, batch_size=1, callbacks=model.get_callbacks(log_path, checkpoint_path))

if __name__ == '__main__':
    main()
